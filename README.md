# RL-Theory-book (rus)

**Status**: main topics covered, requires revision / editing

- [x] Ch. 1: Introduction
- [x] Ch. 2: Meta-heuristics
    - [x] NEAT, WANN
    - [x] CEM, OpenAI-ES, CMA-ES
- [x] Ch. 3: Classic theory
    - [x] Bellman equations
    - [x] RPI, policy improv. theorem
    - [x] Value Iteration, Policy Iteration
    - [x] Temporal Difference, Q-learning, SARSA
    - [x] Eligibility Traces, TD-lambda
- [x] Ch. 4: Value-based
    - [x] DQN
    - [x] Double DQN, Dueling DQN, PER, Noisy DQN, Multi-step DQN
    - [x] c51, QR-DQN, IQN, Rainbow DQN
- [x] Ch. 5: Policy Gradient
    - [x] REINFORCE, A2C, GAE
    - [x] TRPO, PPO
- [x] Ch. 6: Continuous Control
    - [x] DDPG, TD3
    - [x] SAC
- [x] Ch. 7: Model-based
    - [x] Bandits
    - [x] MCTS, AlphaZero, MuZero
    - [x] LQR
- [x] Ch. 8: Next Stage
    - [x] Imitation Learning / Inverse Reinforcement Learning
    - [x] Multi-Task and Hindsight
    - [x] Hierarchical RL
    - [x] Intrinsic Motivation
    - [x] Partial observability
    - [x] Multi-Agent RL
